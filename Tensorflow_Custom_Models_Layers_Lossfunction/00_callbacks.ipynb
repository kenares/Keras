{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras callbacks\n",
    "\n",
    "In Keras, **Callback** is a Python class meant to be subclassed to provide specific functionality, with a set of methods called at various stages of training (including batch/epoch start and ends), testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training. The methods of the [callbacks](https://keras.io/api/callbacks/) can be called at different stages of training/evaluating/inference. Keras has available callbacks and we'll show how you can use it in the following sections.\n",
    "\n",
    "## Model methods that take callbacks\n",
    "Users can supply a list of callbacks to the following `tf.keras.Model` methods:\n",
    "* [`fit()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit), [`fit_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator)\n",
    "Trains the model for a fixed number of epochs (iterations over a dataset, or data yielded batch-by-batch by a Python generator).\n",
    "* [`evaluate()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate), [`evaluate_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate_generator)\n",
    "Evaluates the model for given data or data generator. Outputs the loss and metric values from the evaluation.\n",
    "* [`predict()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict), [`predict_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict_generator)\n",
    "Generates output predictions for the input data or data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    %tnesorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger, \\\n",
    "ReduceLROnPlateau\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np, pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Keras callback applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare the horses or humans dataset\n",
    "\n",
    "splits, info = tfds.load('horses_or_humans', as_supervised=True, with_info=True, split=['train[:80%]', 'train[80%:]', 'test'])\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 150 #@param {type:\"slider\", min:64, max:300, step:1}\n",
    "IMAGE_SIZE = (SIZE, SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(image, label):\n",
    "  image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
    "  return  image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 150, 150, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "  pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dense_units, input_shape=IMAGE_SIZE + (3,)):\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(dense_units, activation='relu'),\n",
    "      tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [TensorBoard](https://keras.io/api/callbacks/tensorboard/)\n",
    "\n",
    "Enable visualizations for TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/26 [==============================] - 18s 635ms/step - loss: 0.6813 - accuracy: 0.5549 - val_loss: 0.6579 - val_accuracy: 0.6878\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 13s 513ms/step - loss: 0.6396 - accuracy: 0.6538 - val_loss: 0.6079 - val_accuracy: 0.7073\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 13s 515ms/step - loss: 0.5910 - accuracy: 0.7332 - val_loss: 0.6513 - val_accuracy: 0.5366\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 14s 525ms/step - loss: 0.5508 - accuracy: 0.7420 - val_loss: 0.4869 - val_accuracy: 0.8049\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 14s 537ms/step - loss: 0.4711 - accuracy: 0.7990 - val_loss: 0.4068 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6c0dee190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "logdir = os.path.join('logs', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)\n",
    "\n",
    "model.fit(train_batches,\n",
    "         epochs=5,\n",
    "         validation_data=validation_batches,\n",
    "         callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Model Checkpoint](https://keras.io/api/callbacks/model_checkpoint/)\n",
    "\n",
    "Callback to save the Keras model or model weights at some frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 14s - loss: 0.6670 - accuracy: 0.5900 - val_loss: 0.6202 - val_accuracy: 0.6780\n",
      "\n",
      "Epoch 00001: saving model to weights.01-0.62.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6a9d370d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_batches,\n",
    "         epochs=1,\n",
    "         validation_data=validation_batches,\n",
    "         verbose=2,\n",
    "         callbacks=[ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.h5', verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 14s - loss: 0.6751 - accuracy: 0.5681 - val_loss: 0.6545 - val_accuracy: 0.7756\n",
      "\n",
      "Epoch 00001: saving model to saved_model\n",
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6cb076be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_batches,\n",
    "         epochs=1,\n",
    "         validation_data=validation_batches,\n",
    "         verbose=2,\n",
    "         callbacks=[ModelCheckpoint('saved_model', verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/26 - 14s - loss: 0.6751 - accuracy: 0.5718 - val_loss: 0.6676 - val_accuracy: 0.6049\n",
      "\n",
      "Epoch 00001: saving model to model.h5\n",
      "Epoch 2/2\n",
      "26/26 - 13s - loss: 0.6350 - accuracy: 0.6934 - val_loss: 0.6163 - val_accuracy: 0.7317\n",
      "\n",
      "Epoch 00002: saving model to model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6caf4b850>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=2, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[ModelCheckpoint('model.h5', verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Early stopping](https://keras.io/api/callbacks/early_stopping/)\n",
    "\n",
    "Stop training when a monitored metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 - 14s - loss: 0.6783 - accuracy: 0.5499 - val_loss: 0.6619 - val_accuracy: 0.8146\n",
      "Epoch 2/50\n",
      "26/26 - 13s - loss: 0.6505 - accuracy: 0.6375 - val_loss: 0.6253 - val_accuracy: 0.8341\n",
      "Epoch 3/50\n",
      "26/26 - 14s - loss: 0.6069 - accuracy: 0.7117 - val_loss: 0.5939 - val_accuracy: 0.6732\n",
      "Epoch 4/50\n",
      "26/26 - 14s - loss: 0.5714 - accuracy: 0.7105 - val_loss: 0.5180 - val_accuracy: 0.9024\n",
      "Epoch 5/50\n",
      "26/26 - 14s - loss: 0.5223 - accuracy: 0.7603 - val_loss: 0.5951 - val_accuracy: 0.5951\n",
      "Epoch 6/50\n",
      "26/26 - 14s - loss: 0.4797 - accuracy: 0.7956 - val_loss: 0.4709 - val_accuracy: 0.6878\n",
      "Epoch 7/50\n",
      "26/26 - 13s - loss: 0.4125 - accuracy: 0.8455 - val_loss: 0.3230 - val_accuracy: 0.9415\n",
      "Epoch 8/50\n",
      "26/26 - 13s - loss: 0.3112 - accuracy: 0.8966 - val_loss: 0.2431 - val_accuracy: 0.9463\n",
      "Epoch 9/50\n",
      "26/26 - 13s - loss: 0.2936 - accuracy: 0.8832 - val_loss: 0.5663 - val_accuracy: 0.6439\n",
      "Epoch 10/50\n",
      "26/26 - 14s - loss: 0.2532 - accuracy: 0.9270 - val_loss: 0.1708 - val_accuracy: 0.9610\n",
      "Epoch 11/50\n",
      "26/26 - 13s - loss: 0.1936 - accuracy: 0.9392 - val_loss: 0.1440 - val_accuracy: 0.9659\n",
      "Epoch 12/50\n",
      "26/26 - 13s - loss: 0.1599 - accuracy: 0.9465 - val_loss: 0.1191 - val_accuracy: 0.9707\n",
      "Epoch 13/50\n",
      "26/26 - 13s - loss: 0.1377 - accuracy: 0.9599 - val_loss: 0.1688 - val_accuracy: 0.9366\n",
      "Epoch 14/50\n",
      "26/26 - 13s - loss: 0.1074 - accuracy: 0.9769 - val_loss: 0.1206 - val_accuracy: 0.9610\n",
      "Epoch 15/50\n",
      "26/26 - 13s - loss: 0.0988 - accuracy: 0.9745 - val_loss: 0.0924 - val_accuracy: 0.9610\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6cace1160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_batches,\n",
    "         epochs=50,\n",
    "         validation_data=validation_batches,\n",
    "         verbose=2,\n",
    "         callbacks=[EarlyStopping(\n",
    "         patience=3,\n",
    "         min_delta=0.05,\n",
    "         baseline=0.8,\n",
    "         mode='min',\n",
    "         monitor='val_loss',\n",
    "         restore_best_weights=True,\n",
    "         verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CSV Logger](https://keras.io/api/callbacks/csv_logger/)\n",
    "\n",
    "Callback that streams epoch results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/26 [==============================] - 14s 515ms/step - loss: 0.6864 - accuracy: 0.5549 - val_loss: 0.6565 - val_accuracy: 0.7659\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 13s 503ms/step - loss: 0.6384 - accuracy: 0.7356 - val_loss: 0.6557 - val_accuracy: 0.5268\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 13s 512ms/step - loss: 0.5819 - accuracy: 0.7163 - val_loss: 0.5380 - val_accuracy: 0.7512\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 13s 511ms/step - loss: 0.5190 - accuracy: 0.7709 - val_loss: 0.5111 - val_accuracy: 0.8049\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 14s 519ms/step - loss: 0.4640 - accuracy: 0.8094 - val_loss: 0.4433 - val_accuracy: 0.8146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6cabe3fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "csv_file = 'training.csv'\n",
    "\n",
    "model.fit(train_batches,\n",
    "         epochs=5,\n",
    "         validation_data=validation_batches,\n",
    "         callbacks=[CSVLogger(csv_file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.608272</td>\n",
       "      <td>0.673407</td>\n",
       "      <td>0.765854</td>\n",
       "      <td>0.656475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.716545</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>0.526829</td>\n",
       "      <td>0.655732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.742092</td>\n",
       "      <td>0.566111</td>\n",
       "      <td>0.751220</td>\n",
       "      <td>0.538003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.750608</td>\n",
       "      <td>0.524267</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.511137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>0.452956</td>\n",
       "      <td>0.814634</td>\n",
       "      <td>0.443315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  accuracy      loss  val_accuracy  val_loss\n",
       "0      0  0.608272  0.673407      0.765854  0.656475\n",
       "1      1  0.716545  0.630930      0.526829  0.655732\n",
       "2      2  0.742092  0.566111      0.751220  0.538003\n",
       "3      3  0.750608  0.524267      0.804878  0.511137\n",
       "4      4  0.802920  0.452956      0.814634  0.443315"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(csv_file).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Learning Rate Scheduler](https://keras.io/api/callbacks/learning_rate_scheduler/)\n",
    "\n",
    "Updates the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.005.\n",
      "26/26 [==============================] - 14s 527ms/step - loss: 0.6763 - accuracy: 0.5602 - val_loss: 0.6773 - val_accuracy: 0.5073\n",
      "Epoch 2/5\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0025.\n",
      "26/26 [==============================] - 14s 526ms/step - loss: 0.6369 - accuracy: 0.6570 - val_loss: 0.6224 - val_accuracy: 0.7122\n",
      "Epoch 3/5\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00125.\n",
      "26/26 [==============================] - 13s 504ms/step - loss: 0.6155 - accuracy: 0.7550 - val_loss: 0.6154 - val_accuracy: 0.7707\n",
      "Epoch 4/5\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000625.\n",
      "26/26 [==============================] - 13s 520ms/step - loss: 0.6028 - accuracy: 0.7482 - val_loss: 0.6161 - val_accuracy: 0.7268\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0003125.\n",
      "26/26 [==============================] - 13s 510ms/step - loss: 0.5899 - accuracy: 0.7698 - val_loss: 0.6168 - val_accuracy: 0.7073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6caab0eb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 1\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1+epoch) / epochs_drop))\n",
    "    return lr\n",
    "\n",
    "model.fit(train_batches,\n",
    "         epochs=5,\n",
    "         validation_data=validation_batches,\n",
    "         callbacks=[LearningRateScheduler(step_decay, verbose=1),\n",
    "                   TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ReduceLROnPlateau](https://keras.io/api/callbacks/reduce_lr_on_plateau/)\n",
    "\n",
    "Reduce learning rate when a metric has stopped improving.\n",
    "**Callback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 14s 539ms/step - loss: 0.6712 - accuracy: 0.5680 - val_loss: 0.7124 - val_accuracy: 0.4390\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 14s 521ms/step - loss: 0.6409 - accuracy: 0.6310 - val_loss: 0.6409 - val_accuracy: 0.5317\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 13s 506ms/step - loss: 0.5642 - accuracy: 0.7286 - val_loss: 0.6085 - val_accuracy: 0.5854\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 13s 511ms/step - loss: 0.5221 - accuracy: 0.7739 - val_loss: 0.6798 - val_accuracy: 0.5220\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 13s 509ms/step - loss: 0.4688 - accuracy: 0.7823 - val_loss: 0.4264 - val_accuracy: 0.8780\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 14s 536ms/step - loss: 0.4117 - accuracy: 0.8951 - val_loss: 0.4036 - val_accuracy: 0.8878\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 14s 527ms/step - loss: 0.3993 - accuracy: 0.8940 - val_loss: 0.3855 - val_accuracy: 0.8927\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 15s 560ms/step - loss: 0.3723 - accuracy: 0.8964 - val_loss: 0.3501 - val_accuracy: 0.9220\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 13s 507ms/step - loss: 0.3673 - accuracy: 0.8754 - val_loss: 0.3729 - val_accuracy: 0.8829\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 13s 502ms/step - loss: 0.3440 - accuracy: 0.9033 - val_loss: 0.3316 - val_accuracy: 0.9073\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 13s 507ms/step - loss: 0.3380 - accuracy: 0.9156 - val_loss: 0.3243 - val_accuracy: 0.9073\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 13s 513ms/step - loss: 0.3279 - accuracy: 0.8910 - val_loss: 0.3114 - val_accuracy: 0.9073\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 13s 507ms/step - loss: 0.3254 - accuracy: 0.9077 - val_loss: 0.3085 - val_accuracy: 0.9073\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 14s 523ms/step - loss: 0.3072 - accuracy: 0.8991 - val_loss: 0.3066 - val_accuracy: 0.9024\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 13s 507ms/step - loss: 0.3041 - accuracy: 0.9191 - val_loss: 0.2942 - val_accuracy: 0.9122\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 13s 510ms/step - loss: 0.3051 - accuracy: 0.9035 - val_loss: 0.2809 - val_accuracy: 0.9317\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 14s 521ms/step - loss: 0.3033 - accuracy: 0.8989 - val_loss: 0.2717 - val_accuracy: 0.9268\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 13s 510ms/step - loss: 0.2784 - accuracy: 0.9229 - val_loss: 0.2778 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 13s 514ms/step - loss: 0.2819 - accuracy: 0.9097 - val_loss: 0.2911 - val_accuracy: 0.8976\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 14s 521ms/step - loss: 0.2671 - accuracy: 0.9321 - val_loss: 0.2645 - val_accuracy: 0.9171\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 13s 512ms/step - loss: 0.2700 - accuracy: 0.9190 - val_loss: 0.2531 - val_accuracy: 0.9268\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 13s 517ms/step - loss: 0.2587 - accuracy: 0.9257 - val_loss: 0.2487 - val_accuracy: 0.9268\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 14s 537ms/step - loss: 0.2552 - accuracy: 0.9297 - val_loss: 0.2409 - val_accuracy: 0.9268\n",
      "Epoch 24/50\n",
      "26/26 [==============================] - 14s 539ms/step - loss: 0.2464 - accuracy: 0.9375 - val_loss: 0.2300 - val_accuracy: 0.9268\n",
      "Epoch 25/50\n",
      "26/26 [==============================] - 14s 537ms/step - loss: 0.2333 - accuracy: 0.9525 - val_loss: 0.2228 - val_accuracy: 0.9317\n",
      "Epoch 26/50\n",
      "26/26 [==============================] - 14s 521ms/step - loss: 0.2245 - accuracy: 0.9477 - val_loss: 0.2154 - val_accuracy: 0.9463\n",
      "Epoch 27/50\n",
      "26/26 [==============================] - 13s 510ms/step - loss: 0.2339 - accuracy: 0.9343 - val_loss: 0.2081 - val_accuracy: 0.9512\n",
      "Epoch 28/50\n",
      "26/26 [==============================] - 14s 528ms/step - loss: 0.2231 - accuracy: 0.9504 - val_loss: 0.2452 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 29/50\n",
      "26/26 [==============================] - 14s 531ms/step - loss: 0.2147 - accuracy: 0.9481 - val_loss: 0.2098 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 30/50\n",
      "26/26 [==============================] - 15s 562ms/step - loss: 0.2135 - accuracy: 0.9464 - val_loss: 0.2003 - val_accuracy: 0.9317\n",
      "Epoch 31/50\n",
      "26/26 [==============================] - 13s 499ms/step - loss: 0.2162 - accuracy: 0.9560 - val_loss: 0.2099 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 32/50\n",
      "26/26 [==============================] - 14s 528ms/step - loss: 0.2034 - accuracy: 0.9531 - val_loss: 0.1819 - val_accuracy: 0.9610\n",
      "Epoch 33/50\n",
      "26/26 [==============================] - 14s 548ms/step - loss: 0.1958 - accuracy: 0.9670 - val_loss: 0.1903 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 34/50\n",
      "26/26 [==============================] - 14s 530ms/step - loss: 0.1902 - accuracy: 0.9620 - val_loss: 0.1870 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 35/50\n",
      "26/26 [==============================] - 14s 546ms/step - loss: 0.1836 - accuracy: 0.9613 - val_loss: 0.1919 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 36/50\n",
      "26/26 [==============================] - 14s 531ms/step - loss: 0.1770 - accuracy: 0.9653 - val_loss: 0.1664 - val_accuracy: 0.9610\n",
      "Epoch 37/50\n",
      "26/26 [==============================] - 14s 548ms/step - loss: 0.1879 - accuracy: 0.9574 - val_loss: 0.1818 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 38/50\n",
      "26/26 [==============================] - 14s 523ms/step - loss: 0.1768 - accuracy: 0.9571 - val_loss: 0.1580 - val_accuracy: 0.9707\n",
      "Epoch 39/50\n",
      "26/26 [==============================] - 13s 510ms/step - loss: 0.1617 - accuracy: 0.9666 - val_loss: 0.1616 - val_accuracy: 0.9463\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 40/50\n",
      "26/26 [==============================] - 13s 511ms/step - loss: 0.1617 - accuracy: 0.9692 - val_loss: 0.1638 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 41/50\n",
      "26/26 [==============================] - 14s 524ms/step - loss: 0.1680 - accuracy: 0.9626 - val_loss: 0.1526 - val_accuracy: 0.9463\n",
      "Epoch 42/50\n",
      "26/26 [==============================] - 14s 536ms/step - loss: 0.1576 - accuracy: 0.9719 - val_loss: 0.1453 - val_accuracy: 0.9659\n",
      "Epoch 43/50\n",
      "26/26 [==============================] - 14s 530ms/step - loss: 0.1688 - accuracy: 0.9593 - val_loss: 0.1450 - val_accuracy: 0.9610\n",
      "Epoch 44/50\n",
      "26/26 [==============================] - 14s 524ms/step - loss: 0.1564 - accuracy: 0.9641 - val_loss: 0.1773 - val_accuracy: 0.9220\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 45/50\n",
      "26/26 [==============================] - 14s 533ms/step - loss: 0.1543 - accuracy: 0.9694 - val_loss: 0.1399 - val_accuracy: 0.9610\n",
      "Epoch 46/50\n",
      "26/26 [==============================] - 14s 519ms/step - loss: 0.1441 - accuracy: 0.9736 - val_loss: 0.1367 - val_accuracy: 0.9659\n",
      "Epoch 47/50\n",
      "26/26 [==============================] - 14s 525ms/step - loss: 0.1323 - accuracy: 0.9810 - val_loss: 0.1306 - val_accuracy: 0.9659\n",
      "Epoch 48/50\n",
      "26/26 [==============================] - 13s 516ms/step - loss: 0.1431 - accuracy: 0.9673 - val_loss: 0.1435 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 49/50\n",
      "26/26 [==============================] - 14s 537ms/step - loss: 0.1472 - accuracy: 0.9683 - val_loss: 0.1445 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 14s 538ms/step - loss: 0.1349 - accuracy: 0.9699 - val_loss: 0.1342 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.001.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa6ca9b4df0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_batches,\n",
    "         epochs=50,\n",
    "         validation_data=validation_batches,\n",
    "         callbacks=[ReduceLROnPlateau(monitor='val_loss',\n",
    "                                     factor=0.2, verbose=1,\n",
    "                                     patience=1, min_lr=0.001),\n",
    "                   TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras model to add callbacks to\n",
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(1, activation = 'linear', input_dim = 784))\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.1), loss='mean_squared_error', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example MNIST data and pre-process it\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's define a simple custom callback to track the start and the end of every batch data. During those calls, it prints the index of the current batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        print(f'Training batch {batch} begins at {datetime.datetime.now().time()}')\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(f'Training batch {batch} ends at {datetime.datetime.now().time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing a callback to model methods such as $tf.keras.Model.fit()$ ensures the methods are called at those stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 0 begins at 14:33:36.656532\n",
      "Training batch 0 ends at 14:33:37.057915\n",
      "Training batch 1 begins at 14:33:37.058091\n",
      "Training batch 1 ends at 14:33:37.059771\n",
      "Training batch 2 begins at 14:33:37.059878\n",
      "Training batch 2 ends at 14:33:37.060954\n",
      "Training batch 3 begins at 14:33:37.061069\n",
      "Training batch 3 ends at 14:33:37.062189\n",
      "Training batch 4 begins at 14:33:37.062525\n",
      "Training batch 4 ends at 14:33:37.063596\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "             batch_size=64,\n",
    "             epochs=1,\n",
    "             steps_per_epoch=5,\n",
    "             verbose=0,\n",
    "             callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **An overview of callback methods**\n",
    "\n",
    "### **Common methods for training/testing/predicting**\n",
    "\n",
    "For training, testing, and predicting, following methods are provided to be overridden.\n",
    "\n",
    "**on_(train|test|predict)_begin(self, logs=None)**\n",
    "Called at the beginning of fit/evaluate/predict.\n",
    "\n",
    "**on_(train|test|predict)_end(self, logs=None)**\n",
    "Called at the end of fit/evaluate/predict.\n",
    "\n",
    "**on_(train|test|predict)_batch_begin(self, batch, logs=None)**\n",
    "Called right before processing a batch during training/testing/predicting.\n",
    "\n",
    "Within this method, logs is a dict with batch and size available keys, representing the current batch number and the size of the batch.\n",
    "\n",
    "**on_(train|test|predict)_batch_end(self, batch, logs=None)**\n",
    "Called at the end of training/testing/predicting a batch. Within this method, logs is a dict containing the stateful metrics result.\n",
    "\n",
    "### **Training specific methods**\n",
    "\n",
    "In addition, for training, following are provided.\n",
    "\n",
    "**on_epoch_begin(self, epoch, logs=None)**\n",
    "Called at the beginning of an epoch during training.\n",
    "\n",
    "**on_epoch_end(self, epoch, logs=None)**\n",
    "Called at the end of an epoch during training.\n",
    "\n",
    "### Usage of `logs` dict\n",
    "The `logs` dict contains the loss value, and all the metrics at the end of a batch or epoch. Example includes the loss and mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Val/Train loss ratio: 0.48\n",
      "Epoch: 1, Val/Train loss ratio: 0.13\n",
      "Epoch: 2, Val/Train loss ratio: 1.81\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end = lambda epoch, logs:\n",
    "    print('Epoch: {}, Val/Train loss ratio: {:.2f}'.format(epoch, logs['val_loss'] / logs['loss']))\n",
    ")\n",
    "\n",
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train, \n",
    "             validation_data=(x_test, y_test),\n",
    "             batch_size=64,\n",
    "             epochs=3,\n",
    "             verbose=0,\n",
    "             callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Val/Train loss ratio: 1.41\n",
      "Stopping training...\n"
     ]
    }
   ],
   "source": [
    "class DetectOverfittingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, threshold=0.7):\n",
    "        super(DetectOverfittingCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ratio = logs['val_loss'] / logs['loss']\n",
    "        print('Epoch: {}, Val/Train loss ratio: {:.2f}'.format(epoch, ratio))\n",
    "        \n",
    "        if ratio > self.threshold:\n",
    "            print('Stopping training...')\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train, \n",
    "             validation_data=(x_test, y_test),\n",
    "             batch_size=64,\n",
    "             epochs=3,\n",
    "             verbose=0,\n",
    "             callbacks=[DetectOverfittingCallback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "technical-test",
   "language": "python",
   "name": "technical-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
