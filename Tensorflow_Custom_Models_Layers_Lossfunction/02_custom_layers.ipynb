{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Flatten, Lambda, Dropout\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'simple_dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.03313166]], dtype=float32)>, <tf.Variable 'simple_dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "class SimpleDense(Layer):\n",
    "    \n",
    "    def __init__(self, units=32):\n",
    "        super(SimpleDense, self).__init__()\n",
    "        self.units = units\n",
    "        \n",
    "    #We use def build(self, input_shape): to create the state of the layers and specify local input states.\n",
    "    def build(self, input_shape): # Create the state of the layer (weights)\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(name='kernel',\n",
    "                            initial_value=w_init(shape=(input_shape[-1], self.units),\n",
    "                                                dtype='float32'),\n",
    "                            trainable=True)\n",
    "        \n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(name='bias',\n",
    "                            initial_value=b_init(shape=(self.units,), dtype='float32'),\n",
    "                            trainable=True)\n",
    "    \n",
    "    def call(self, inputs): # Defines the computation from inputs to outputs\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "        \n",
    "my_dense = SimpleDense(units=1)\n",
    "x = tf.ones((1, 1))\n",
    "y = my_dense(x)\n",
    "\n",
    "print(my_dense.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ 2x - 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys =  np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.9814]]\n",
      "[<tf.Variable 'simple_dense_1/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9973042]], dtype=float32)>, <tf.Variable 'simple_dense_1/bias:0' shape=(1,) dtype=float32, numpy=array([-0.99164236], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "my_layer = SimpleDense(1)\n",
    "\n",
    "model = tf.keras.models.Sequential([my_layer])\n",
    "model.compile(optimizer='sgd',\n",
    "                loss='mean_squared_error')\n",
    "model.fit(xs, ys, epochs=500, verbose=0)\n",
    "\n",
    "print(model.predict([10.0]))\n",
    "print(my_layer.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4323 - accuracy: 0.8756\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1209 - accuracy: 0.9640\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0892 - accuracy: 0.9716\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0724 - accuracy: 0.9777\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0634 - accuracy: 0.9791\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0730 - accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07302159070968628, 0.9786999821662903]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "custom_layer = SimpleDense(128)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    custom_layer,\n",
    "    Lambda(lambda x: tf.abs(x)),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'simple_dense_2/kernel:0' shape=(784, 128) dtype=float32, numpy=\n",
      "array([[-0.01821556, -0.06078629,  0.03296904, ..., -0.03211952,\n",
      "        -0.00411339,  0.01171576],\n",
      "       [-0.09093087, -0.0100612 ,  0.08894789, ...,  0.02703124,\n",
      "         0.08309151,  0.00784083],\n",
      "       [-0.10543244,  0.01748854, -0.04546477, ...,  0.01973497,\n",
      "         0.04790882,  0.00461827],\n",
      "       ...,\n",
      "       [-0.05366775,  0.00759535, -0.0601759 , ..., -0.07406662,\n",
      "        -0.05222664, -0.02748975],\n",
      "       [ 0.02620558, -0.00838865, -0.03226786, ...,  0.00813237,\n",
      "        -0.03600022,  0.04739312],\n",
      "       [-0.07122918, -0.00015546,  0.0477097 , ..., -0.08269745,\n",
      "        -0.02607518,  0.08252136]], dtype=float32)>, <tf.Variable 'simple_dense_2/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([-1.40060455e-01,  1.15310319e-01, -5.81937358e-02, -4.39076722e-02,\n",
      "       -9.18452516e-02, -1.29172310e-01, -1.29385535e-02, -1.10927880e-01,\n",
      "        6.23607077e-03,  7.23845288e-02,  2.28855424e-02, -3.78958769e-02,\n",
      "       -6.78299144e-02, -1.35236263e-01, -1.49784774e-01, -1.97653398e-01,\n",
      "       -3.16584599e-04,  1.77335709e-01, -5.18146064e-03, -8.98275301e-02,\n",
      "        1.35515444e-02, -1.12827331e-01,  5.94936647e-02, -2.68163886e-02,\n",
      "       -9.73789990e-02,  2.57983673e-02,  4.02157605e-02, -1.59694515e-02,\n",
      "       -9.86521393e-02,  1.95080981e-01,  6.64309561e-02,  1.78819746e-01,\n",
      "        6.06059916e-02,  6.07704557e-02, -1.63372830e-01, -2.64880776e-01,\n",
      "       -1.47570312e-01, -2.04809681e-01, -2.28566211e-02,  1.51941657e-01,\n",
      "       -1.20007850e-01,  2.73980796e-01,  1.80379525e-02,  1.63552418e-01,\n",
      "        8.98060948e-02,  5.80881946e-02, -2.84400657e-02,  3.43978554e-02,\n",
      "       -7.25245755e-03, -8.40551034e-02, -2.99266372e-02,  9.85751674e-02,\n",
      "        3.21475533e-03,  2.51826067e-02,  1.14952236e-01,  9.32949930e-02,\n",
      "        6.73864633e-02, -7.50212669e-02, -6.35792390e-02, -1.23342559e-01,\n",
      "        6.28095046e-02, -2.31714118e-02, -8.51139948e-02,  3.99874821e-02,\n",
      "       -8.61333311e-02,  4.52446453e-02, -5.12574688e-02,  2.14964151e-02,\n",
      "        1.60805538e-01, -1.89459831e-01,  1.17961196e-02, -4.52814102e-02,\n",
      "        6.00532116e-03, -8.57696030e-03,  9.04519781e-02, -2.42817961e-02,\n",
      "        1.36219874e-01, -6.16712496e-02,  5.06363027e-02, -3.72254215e-02,\n",
      "       -9.92065892e-02, -1.94311957e-03,  2.66676390e-04, -1.27107367e-01,\n",
      "        1.28161442e-02, -9.34209526e-02,  1.40602402e-02,  8.58632401e-02,\n",
      "       -1.00416481e-01,  3.21790949e-02,  2.37709470e-02,  1.68457590e-02,\n",
      "       -1.79095641e-02, -1.62109807e-01, -1.12046152e-02,  4.00788821e-02,\n",
      "        2.45329395e-01,  5.64945638e-02, -1.88152149e-01,  1.19430758e-01,\n",
      "        7.60200843e-02,  4.15923521e-02,  8.69214758e-02,  8.79794881e-02,\n",
      "        3.20117325e-02,  4.12414186e-02, -6.44564629e-02,  2.16025971e-02,\n",
      "       -3.99594381e-02,  1.02580875e-01,  6.37827739e-02, -9.76608172e-02,\n",
      "        9.84019786e-02, -2.57173106e-02,  6.80382997e-02,  6.98974431e-02,\n",
      "        8.91839713e-03,  1.10076845e-01,  9.09624062e-03, -6.13742620e-02,\n",
      "        3.81717924e-03, -5.15634753e-02,  4.23401855e-02,  3.39525230e-02,\n",
      "       -9.04601291e-02, -1.85201317e-01,  7.89384991e-02,  7.51240999e-02],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(custom_layer.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDenseWithActivation(Layer):\n",
    "    # add an activation parameter\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        super(SimpleDenseWithActivation, self).__init__() #The super keyword is used for inheriting functionalities from Keras’s Layer class.\n",
    "        self.units = units\n",
    "        \n",
    "        # define the activation to get from the built-in activation layers in Keras\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(name='kernel',\n",
    "                            initial_value=w_init(shape=(input_shape[-1], self.units),\n",
    "                                                dtype='float32'),\n",
    "                            trainable=True)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(name='bias',\n",
    "                            initial_value=b_init(shape=(self.units,),\n",
    "                                                dtype='float32'),\n",
    "                            trainable=True)\n",
    "        super().build(input_shape) #The super keyword is used for inheriting functionalities from Keras’s Layer class.\n",
    "        \n",
    "    def call(self, inputs): # Defines the computation from inputs to outputs --> call during training\n",
    "        # pass the computation to the activation layer\n",
    "        return self.activation(tf.matmul(inputs, self.w) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4589 - accuracy: 0.8686\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1314 - accuracy: 0.9618\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0898 - accuracy: 0.9729\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0703 - accuracy: 0.9788\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0584 - accuracy: 0.9820\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0655 - accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06553016602993011, 0.9799000024795532]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    SimpleDenseWithActivation(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Layer\n",
    "\n",
    "$ax^2 + bx + c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleQuadratic(Layer):\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        super(SimpleQuadratic, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):  \n",
    "        a_init = tf.random_normal_initializer()\n",
    "        self.a = tf.Variable(name='a_kernel', \n",
    "                            initial_value=a_init(shape=(input_shape[-1], self.units),\n",
    "                                                  dtype='float32'),\n",
    "                            trainable=True)\n",
    "        \n",
    "        b_init = tf.random_normal_initializer()\n",
    "        self.b = tf.Variable(name='b_kernel',\n",
    "                            initial_value=b_init(shape=(input_shape[-1], self.units),\n",
    "                                                dtype='float32'),\n",
    "                            trainable=True)\n",
    "        \n",
    "        c_init = tf.zeros_initializer()\n",
    "        self.c = tf.Variable(name='bias',\n",
    "                            initial_value=c_init(shape=(self.units,),\n",
    "                                                dtype='float32'),\n",
    "                            trainable=True)\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x_squared = K.square(inputs)\n",
    "        return self.activation(tf.matmul(x_squared, self.a) + tf.matmul(inputs, self.b) + self.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3952 - accuracy: 0.8833\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1246 - accuracy: 0.9626\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0854 - accuracy: 0.9744\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0642 - accuracy: 0.9794\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0518 - accuracy: 0.9840\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0729 - accuracy: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07285595685243607, 0.9794999957084656]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    SimpleQuadratic(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "technical-test",
   "language": "python",
   "name": "technical-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
